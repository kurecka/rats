{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.stats import t\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Morningside\n",
       "1       Morningside\n",
       "2       Morningside\n",
       "3       Morningside\n",
       "4       Morningside\n",
       "           ...     \n",
       "1615         Harlem\n",
       "1616         Harlem\n",
       "1617         Harlem\n",
       "1618         Harlem\n",
       "1619         Harlem\n",
       "Name: instance, Length: 1620, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "output_path = Path('../outputs/20240712-115425-manhattan_lp_fixed2')\n",
    "\n",
    "data = pd.read_csv(output_path / 'results.csv')\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "data['algorithm'] = data.agent + '_t' + data.time_limit.astype(str)\n",
    "data.loc[data.agent == 'LP', 'algorithm'] = 'LP'\n",
    "data['benchmark'] = data.env + '_' + data.instance + '_cons_thd=' + \\\n",
    "                    data.cons_thd.astype(str) + '_p=' + data.period.astype(str) + '_rad=' + data.radius.astype(str)\n",
    "\n",
    "data['feasible'] = data.penalty_mean <= data.c\n",
    "\n",
    "data['t'] = (data['penalty_mean'] - data['c']) * np.sqrt(data['repetitions']) / data['penalty_std']\n",
    "data.loc[data['penalty_std'] == 0, 't'] = 0\n",
    "\n",
    "data['feasible_low'] = data['t'] <= t(df=data['repetitions']-1).ppf(0.95)\n",
    "data['feasible_high'] = data['t'] <= t(df=data['repetitions']-1).ppf(0.05)\n",
    "data.loc[data.agent == 'LP', 'feasible_low'] = True\n",
    "data.loc[data.agent == 'LP', 'feasible_high'] = True\n",
    "\n",
    "data.head()\n",
    "data['feasible_low'].value_counts()\n",
    "data[data.c == 10]['feasible'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morningside\n",
      "          algorithm        cr  esat  sat  strongsat\n",
      "0    DualUCT_t1000  0.018609    24   24          6\n",
      "1     DualUCT_t200  0.015832    24   24          6\n",
      "2     DualUCT_t500  0.027219    24   24          6\n",
      "3  ParetoUCT_t1000  6.784872    21   21         15\n",
      "4   ParetoUCT_t200  7.184556    25   28         23\n",
      "5   ParetoUCT_t500  6.958189    21   23         18\n",
      "6      RAMCP_t1000  6.434356    31   31         30\n",
      "7       RAMCP_t200  5.531113    33   33         32\n",
      "8       RAMCP_t500  5.881078    31   32         31\n",
      "Lexington\n",
      "          algorithm        cr  esat  sat  strongsat\n",
      "0    DualUCT_t1000  1.013782    12   12         12\n",
      "1     DualUCT_t200  0.877128    10   11          8\n",
      "2     DualUCT_t500  1.004338    12   12         10\n",
      "3  ParetoUCT_t1000  5.348625    22   24         19\n",
      "4   ParetoUCT_t200  5.158923    27   27         24\n",
      "5   ParetoUCT_t500  5.641095    23   26         21\n",
      "6      RAMCP_t1000  4.641480    31   31         30\n",
      "7       RAMCP_t200  4.787576    32   34         32\n",
      "8       RAMCP_t500  4.363730    31   31         31\n",
      "50thStreet\n",
      "          algorithm        cr  esat  sat  strongsat\n",
      "0    DualUCT_t1000  0.241362    24   24         12\n",
      "1     DualUCT_t200  0.231082    22   24          9\n",
      "2     DualUCT_t500  0.252471    24   24         12\n",
      "3  ParetoUCT_t1000  5.138928    13   19          8\n",
      "4   ParetoUCT_t200  4.437609    17   20         13\n",
      "5   ParetoUCT_t500  5.043659    16   20         11\n",
      "6      RAMCP_t1000  3.836561    20   23         18\n",
      "7       RAMCP_t200  3.803231    26   26         22\n",
      "8       RAMCP_t500  3.832672    23   24         20\n",
      "Pulitzer\n",
      "          algorithm        cr  esat  sat  strongsat\n",
      "0    DualUCT_t1000  0.610769    18   19         17\n",
      "1     DualUCT_t200  0.596047    16   19         15\n",
      "2     DualUCT_t500  0.627155    18   20         17\n",
      "3  ParetoUCT_t1000  3.567415     9   13          7\n",
      "4   ParetoUCT_t200  4.477043    15   22         14\n",
      "5   ParetoUCT_t500  3.848776    14   16          8\n",
      "6      RAMCP_t1000  4.471497    25   26         24\n",
      "7       RAMCP_t200  4.831739    31   32         30\n",
      "8       RAMCP_t500  4.688698    28   28         27\n",
      "Harlem\n",
      "          algorithm        cr  esat  sat  strongsat\n",
      "0    DualUCT_t1000  0.161649    13   14          1\n",
      "1     DualUCT_t200  0.135263    13   14          0\n",
      "2     DualUCT_t500  0.149706    13   14          1\n",
      "3  ParetoUCT_t1000  4.777292    27   29         26\n",
      "4   ParetoUCT_t200  3.374099    35   35         31\n",
      "5   ParetoUCT_t500  4.230403    30   31         28\n",
      "6      RAMCP_t1000  2.404204    36   36         36\n",
      "7       RAMCP_t200  1.893977    36   36         36\n",
      "8       RAMCP_t500  2.155340    36   36         35\n",
      "\n",
      " table.csv \n",
      "          algorithm        cr  esat  sat  strongsat\n",
      "0    DualUCT_t1000  0.409234    91   93         48\n",
      "1     DualUCT_t200  0.371071    85   92         38\n",
      "2     DualUCT_t500  0.412178    91   94         46\n",
      "3  ParetoUCT_t1000  5.123426    92  106         75\n",
      "4   ParetoUCT_t200  4.926446   119  132        105\n",
      "5   ParetoUCT_t500  5.144425   104  116         86\n",
      "6      RAMCP_t1000  4.357619   143  147        138\n",
      "7       RAMCP_t200  4.169527   158  161        152\n",
      "8       RAMCP_t500  4.184303   149  151        144\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def get_table(data):\n",
    "    # get sum of rewards on benchmarks we admit as solved\n",
    "    feasible_data = data[data['feasible_low'] == True]\n",
    "    reward_sum_by_algorithm = feasible_data.groupby('algorithm')['reward_mean'].sum().reset_index()\n",
    "\n",
    "    # get total number of runs of each algorithm (is the same value for all algorithms)\n",
    "    total_rows_by_algorithm = data['algorithm'].value_counts().reset_index()\n",
    "    total_rows_by_algorithm.columns = ['algorithm', 'total_rows']\n",
    "\n",
    "    reward_sum_by_algorithm = pd.merge(reward_sum_by_algorithm, total_rows_by_algorithm, on='algorithm')\n",
    "    reward_sum_by_algorithm['cr'] = reward_sum_by_algorithm['reward_mean'] / reward_sum_by_algorithm['total_rows']\n",
    "    reward_result = reward_sum_by_algorithm[['algorithm', 'cr']]\n",
    "\n",
    "    aggregate_table = data.groupby('algorithm').agg(\n",
    "        esat=pd.NamedAgg(column='feasible', aggfunc='sum'),\n",
    "        sat=pd.NamedAgg(column='feasible_low', aggfunc='sum'),\n",
    "        strongsat=pd.NamedAgg(column='feasible_high', aggfunc='sum'),\n",
    "    ).reset_index()\n",
    "\n",
    "    final_result = pd.merge(reward_result, aggregate_table, on='algorithm', how='outer')\n",
    "\n",
    "    return final_result.sort_values(by='algorithm')\n",
    "\n",
    "tables = {\n",
    "    'table.csv': get_table(data),\n",
    "}\n",
    "\n",
    "\n",
    "for instance in data.instance.unique():\n",
    "    print(instance + \"\\n\", get_table(data[data.instance == instance]))\n",
    "for name, table in tables.items():\n",
    "    table.to_csv(output_path / name)\n",
    "    print('\\n', name, '\\n', table)\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot meand reward vs. c\n",
    "# Each benchmark is a subplot\n",
    "# Each algorithm is a line\n",
    "# Use `reward_std` for error bars\n",
    "\n",
    "\n",
    "for time in [t for t in data['time_limit'].unique() if t >= 0]:\n",
    "    filtered_data = data[(data['time_limit'] == time) | (data['time_limit'] == -1)]\n",
    "    filtered_data['reward_std'] /= np.sqrt(filtered_data['repetitions'])\n",
    "\n",
    "    default_palette = sns.color_palette()\n",
    "    algorithms = filtered_data['algorithm'].unique()\n",
    "    palette = {algorithm: default_palette[i] for i, algorithm in enumerate(algorithms)}\n",
    "\n",
    "\n",
    "    # Create a FacetGrid with the benchmark feature\n",
    "    g = sns.FacetGrid(filtered_data, col=\"benchmark\", col_wrap=4, height=4, aspect=1.5)\n",
    "\n",
    "    # Do not show the plot in a notebook\n",
    "    plt.ioff()\n",
    "\n",
    "    # Iterate through each subplot to add error bars manually\n",
    "    for ax, (benchmark_value, subset) in zip(g.axes.flatten(), filtered_data.sort_values(by='instance').groupby('benchmark')):\n",
    "        sns.lineplot(x='c', y='reward_mean', hue='algorithm', palette=palette, err_style=None, data=subset, ax=ax)\n",
    "\n",
    "        non_feasible = subset[subset['feasible_low'] == False]\n",
    "        sns.scatterplot(x='c', y='reward_mean', hue='algorithm', palette=palette, marker='x', s=50, data=non_feasible, ax=ax)\n",
    "        ax.grid(True)\n",
    "\n",
    "        for alg in algorithms:\n",
    "            alg_data = subset[subset['algorithm'] == alg]\n",
    "            ax.fill_between(\n",
    "                alg_data['c'],\n",
    "                alg_data['reward_mean'] - alg_data['reward_std'],\n",
    "                alg_data['reward_mean'] + alg_data['reward_std'],\n",
    "                alpha=0.2,\n",
    "                color=palette[alg]\n",
    "            )\n",
    "\n",
    "    # Adjust the titles and labels\n",
    "    g.set_titles(col_template=\"{col_name}\")\n",
    "    g.set_axis_labels(\"C\", \"Mean Reward\")\n",
    "\n",
    "    g.savefig(output_path / f'mean_reward_vs_c_t{time}.svg')\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"default\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
